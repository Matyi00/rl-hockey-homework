{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dreamer as dm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from importlib import reload\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath('../hockey_env/hockey'))\n",
    "import hockey_env as h_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Loss: 6.636325836181641\n",
      "Step 0 Loss: 4.547894477844238\n",
      "Step 0 Loss: 3.357950448989868\n",
      "Step 0 Loss: 3.6433939933776855\n",
      "Step 0 Loss: 2.989323139190674\n",
      "Step 0 Loss: 2.8681836128234863\n",
      "Step 0 Loss: 2.3604557514190674\n",
      "Step 0 Loss: 3.323962926864624\n",
      "Step 0 Loss: 4.372046947479248\n",
      "Step 0 Loss: 4.157834529876709\n",
      "Step 0 Loss: 3.5573832988739014\n",
      "Step 0 Loss: 2.0038647651672363\n",
      "Step 0 Loss: 2.8020286560058594\n",
      "Step 0 Loss: 2.6305806636810303\n",
      "Step 0 Loss: 2.525247812271118\n",
      "Step 0 Loss: 2.1822428703308105\n",
      "Step 0 Loss: 1.531864047050476\n",
      "Step 0 Loss: 2.2495381832122803\n",
      "Step 0 Loss: 1.7219271659851074\n",
      "Step 0 Loss: 1.596487045288086\n",
      "Step 0 Loss: 1.5362334251403809\n",
      "Step 0 Loss: 1.3977090120315552\n",
      "Step 0 Loss: 1.6391894817352295\n",
      "Step 0 Loss: 1.5977519750595093\n",
      "Step 0 Loss: 0.9131596088409424\n",
      "Step 0 Loss: 1.401651382446289\n",
      "Step 0 Loss: 1.199601650238037\n",
      "Step 0 Loss: 1.1845207214355469\n",
      "Step 0 Loss: 0.8611408472061157\n",
      "Step 0 Loss: 1.1600849628448486\n",
      "Step 0 Loss: 0.7681677341461182\n",
      "Step 0 Loss: 1.1206715106964111\n",
      "Step 0 Loss: 0.6022509932518005\n",
      "Step 0 Loss: 0.9523634314537048\n",
      "Step 0 Loss: 0.46529683470726013\n",
      "Step 0 Loss: 0.8261139392852783\n",
      "Step 0 Loss: 0.641663670539856\n",
      "Step 0 Loss: 0.560580313205719\n",
      "Step 0 Loss: 0.8501482605934143\n",
      "Step 0 Loss: 0.6715314984321594\n",
      "Step 0 Loss: 0.324138343334198\n",
      "Step 0 Loss: 0.4190951883792877\n",
      "Step 0 Loss: 0.2713782489299774\n",
      "Step 0 Loss: 0.2724436819553375\n",
      "Step 0 Loss: 0.5062277913093567\n",
      "Step 0 Loss: 0.49297991394996643\n",
      "Step 0 Loss: 0.23476040363311768\n",
      "Step 0 Loss: 0.22714637219905853\n",
      "Step 0 Loss: 0.22583867609500885\n",
      "Step 0 Loss: 0.3704493045806885\n",
      "Step 0 Loss: 0.20556527376174927\n",
      "Step 0 Loss: 0.2933315336704254\n",
      "Step 0 Loss: 0.20116102695465088\n",
      "Step 0 Loss: 0.186959370970726\n",
      "Step 0 Loss: 0.23232685029506683\n",
      "Step 0 Loss: 0.17402386665344238\n",
      "Step 0 Loss: 0.1680546998977661\n",
      "Step 0 Loss: 0.2676561772823334\n",
      "Step 0 Loss: 0.3132612407207489\n",
      "Step 0 Loss: 0.6060783863067627\n",
      "Step 0 Loss: 0.3917170763015747\n",
      "Step 0 Loss: 0.13997220993041992\n",
      "Step 0 Loss: 0.29554131627082825\n",
      "Step 0 Loss: 0.1599334478378296\n",
      "Step 0 Loss: 0.22638817131519318\n",
      "Step 0 Loss: 0.1344175487756729\n",
      "Step 0 Loss: 0.17393065989017487\n",
      "Step 0 Loss: 0.27347537875175476\n",
      "Step 0 Loss: 0.10127848386764526\n",
      "Step 0 Loss: 0.251029908657074\n",
      "Step 0 Loss: 0.18042102456092834\n",
      "Step 0 Loss: 0.1413813829421997\n",
      "Step 0 Loss: 0.1342494934797287\n",
      "Step 0 Loss: 0.2072019875049591\n",
      "Step 0 Loss: 0.10460048913955688\n",
      "Step 0 Loss: 0.20046992599964142\n",
      "Step 0 Loss: 0.09335966408252716\n",
      "Step 0 Loss: 0.09715597331523895\n",
      "Step 0 Loss: 0.060953520238399506\n",
      "Step 0 Loss: 0.1338101029396057\n",
      "Step 0 Loss: 0.11410750448703766\n",
      "Step 0 Loss: 0.06190495193004608\n",
      "Step 0 Loss: 0.2085474729537964\n",
      "Step 0 Loss: 0.12593036890029907\n",
      "Step 0 Loss: 0.06453166157007217\n",
      "Step 0 Loss: 0.09735721349716187\n",
      "Step 0 Loss: 0.1256672888994217\n",
      "Step 0 Loss: 0.12787078320980072\n",
      "Step 0 Loss: 0.1872050166130066\n",
      "Step 0 Loss: 0.12271791696548462\n",
      "Step 0 Loss: 0.1459360122680664\n",
      "Step 0 Loss: 0.08914337307214737\n",
      "Step 0 Loss: 0.09165936708450317\n",
      "Step 0 Loss: 0.08604536950588226\n",
      "Step 0 Loss: 0.04537224769592285\n",
      "Step 0 Loss: 0.07918195426464081\n",
      "Step 0 Loss: 0.03873442858457565\n",
      "Step 0 Loss: 0.09738381952047348\n",
      "Step 0 Loss: 0.07834243774414062\n",
      "Step 0 Loss: 0.09939172863960266\n",
      "Step 0 Loss: 0.16938665509223938\n",
      "Step 0 Loss: 0.03869648277759552\n",
      "Step 0 Loss: 0.0488564558327198\n",
      "Step 0 Loss: 0.04952176660299301\n",
      "Step 0 Loss: 0.05110039561986923\n",
      "Step 0 Loss: 0.05195512995123863\n",
      "Step 0 Loss: 0.06921377778053284\n",
      "Step 0 Loss: 0.11354824900627136\n",
      "Step 0 Loss: 0.05129408836364746\n",
      "Step 0 Loss: 0.07696923613548279\n",
      "Step 0 Loss: 0.03439567610621452\n",
      "Step 0 Loss: 0.033606015145778656\n",
      "Step 0 Loss: 0.11469322443008423\n",
      "Step 0 Loss: 0.15163922309875488\n",
      "Step 0 Loss: 0.07245910167694092\n",
      "Step 0 Loss: 0.036291297525167465\n",
      "Step 0 Loss: 0.10402581095695496\n",
      "Step 0 Loss: 0.07678071409463882\n",
      "Step 0 Loss: 0.07236076146364212\n",
      "Step 0 Loss: 0.056562621146440506\n",
      "Step 0 Loss: 0.11092545092105865\n",
      "Step 0 Loss: 0.07510332018136978\n",
      "Step 0 Loss: 0.037571944296360016\n",
      "Step 0 Loss: 0.04698503762483597\n",
      "Step 0 Loss: 0.08918166160583496\n",
      "Step 0 Loss: 0.06131110340356827\n",
      "Step 0 Loss: 0.1654455065727234\n",
      "Step 0 Loss: 0.029947441071271896\n",
      "Step 0 Loss: 0.06661480665206909\n",
      "Step 0 Loss: 0.040469180792570114\n",
      "Step 0 Loss: 0.04652577266097069\n",
      "Step 0 Loss: 0.05515038222074509\n",
      "Step 0 Loss: 0.02282419055700302\n",
      "Step 0 Loss: 0.05576391890645027\n",
      "Step 0 Loss: 0.03455395624041557\n",
      "Step 0 Loss: 0.12366672605276108\n",
      "Step 0 Loss: 0.033958546817302704\n",
      "Step 0 Loss: 0.04216775670647621\n",
      "Step 0 Loss: 0.040657348930835724\n",
      "Step 0 Loss: 0.059429652988910675\n",
      "Step 0 Loss: 0.04455738887190819\n",
      "Step 0 Loss: 0.05136660858988762\n",
      "Step 0 Loss: 0.0589413046836853\n",
      "Step 0 Loss: 0.038791779428720474\n",
      "Step 0 Loss: 0.04308221861720085\n",
      "Step 0 Loss: 0.04276848956942558\n",
      "Step 0 Loss: 0.03622779622673988\n",
      "Step 0 Loss: 0.04933924600481987\n",
      "Step 0 Loss: 0.02633863501250744\n",
      "Step 0 Loss: 0.021704211831092834\n",
      "Step 0 Loss: 0.029408304020762444\n",
      "Step 0 Loss: 0.01839871145784855\n",
      "Step 0 Loss: 0.050341226160526276\n",
      "Step 0 Loss: 0.026357322931289673\n",
      "Step 0 Loss: 0.022085297852754593\n",
      "Step 0 Loss: 0.049997542053461075\n",
      "Step 0 Loss: 0.061303213238716125\n",
      "Step 0 Loss: 0.03229181841015816\n",
      "Step 0 Loss: 0.036568865180015564\n",
      "Step 0 Loss: 0.02043331041932106\n",
      "Step 0 Loss: 0.02558608539402485\n",
      "Step 0 Loss: 0.03733295947313309\n",
      "Step 0 Loss: 0.02545950561761856\n",
      "Step 0 Loss: 0.02031693235039711\n",
      "Step 0 Loss: 0.03758200258016586\n",
      "Step 0 Loss: 0.08096961677074432\n",
      "Step 0 Loss: 0.020616276189684868\n",
      "Step 0 Loss: 0.03591783344745636\n",
      "Step 0 Loss: 0.025458376854658127\n",
      "Step 0 Loss: 0.03185470029711723\n",
      "Step 0 Loss: 0.02613096870481968\n",
      "Step 0 Loss: 0.015100785531103611\n",
      "Step 0 Loss: 0.0473468191921711\n",
      "Step 0 Loss: 0.012991266325116158\n",
      "Step 0 Loss: 0.017071396112442017\n",
      "Step 0 Loss: 0.032836008816957474\n",
      "Step 0 Loss: 0.03708663210272789\n",
      "Step 0 Loss: 0.03390081226825714\n",
      "Step 0 Loss: 0.02864748239517212\n",
      "Step 0 Loss: 0.022567111998796463\n",
      "Step 0 Loss: 0.02237536758184433\n",
      "Step 0 Loss: 0.02465059794485569\n",
      "Step 0 Loss: 0.022801600396633148\n",
      "Step 0 Loss: 0.019990678876638412\n",
      "Step 0 Loss: 0.027309361845254898\n",
      "Step 0 Loss: 0.026855390518903732\n",
      "Step 0 Loss: 0.020458580926060677\n",
      "Step 0 Loss: 0.0207987017929554\n",
      "Step 0 Loss: 0.022990884259343147\n",
      "Step 0 Loss: 0.028589067980647087\n",
      "Step 0 Loss: 0.05477599427103996\n",
      "Step 0 Loss: 0.011440704576671124\n",
      "Step 0 Loss: 0.020739616826176643\n",
      "Step 0 Loss: 0.009658199734985828\n",
      "Step 0 Loss: 0.01940949261188507\n",
      "Step 0 Loss: 0.01851932518184185\n",
      "Step 0 Loss: 0.016173509880900383\n",
      "Step 0 Loss: 0.014264707453548908\n",
      "Step 0 Loss: 0.013514317572116852\n",
      "Step 0 Loss: 0.05124100297689438\n",
      "Step 0 Loss: 0.02518979087471962\n",
      "Step 0 Loss: 0.007921316660940647\n",
      "Step 0 Loss: 0.010043196380138397\n",
      "Step 0 Loss: 0.011572538875043392\n",
      "Step 0 Loss: 0.027170607820153236\n",
      "Step 0 Loss: 0.008595707826316357\n",
      "Step 0 Loss: 0.020436855033040047\n",
      "Step 0 Loss: 0.016471415758132935\n",
      "Step 0 Loss: 0.012772236950695515\n",
      "Step 0 Loss: 0.01331661269068718\n",
      "Step 0 Loss: 0.010770987719297409\n",
      "Step 0 Loss: 0.01871182583272457\n",
      "Step 0 Loss: 0.01984240673482418\n",
      "Step 0 Loss: 0.00872720591723919\n",
      "Step 0 Loss: 0.019047334790229797\n",
      "Step 0 Loss: 0.04459569603204727\n",
      "Step 0 Loss: 0.020303763449192047\n",
      "Step 0 Loss: 0.013001673854887486\n",
      "Step 0 Loss: 0.013703771866858006\n",
      "Step 0 Loss: 0.017259489744901657\n",
      "Step 0 Loss: 0.00832756794989109\n",
      "Step 0 Loss: 0.014466268010437489\n",
      "Step 0 Loss: 0.01936042122542858\n",
      "Step 0 Loss: 0.014118102379143238\n",
      "Step 0 Loss: 0.008762856014072895\n",
      "Step 0 Loss: 0.01566413789987564\n",
      "Step 0 Loss: 0.012074056081473827\n",
      "Step 0 Loss: 0.015067372471094131\n",
      "Step 0 Loss: 0.011013628914952278\n",
      "Step 0 Loss: 0.009638114832341671\n",
      "Step 0 Loss: 0.030976835638284683\n",
      "Step 0 Loss: 0.01482453290373087\n",
      "Step 0 Loss: 0.008644337765872478\n",
      "Step 0 Loss: 0.017662955448031425\n",
      "Step 0 Loss: 0.011760540306568146\n",
      "Step 0 Loss: 0.010830603539943695\n",
      "Step 0 Loss: 0.006787457037717104\n",
      "Step 0 Loss: 0.024133270606398582\n",
      "Step 0 Loss: 0.008900314569473267\n",
      "Step 0 Loss: 0.013219333253800869\n",
      "Step 0 Loss: 0.00906751211732626\n",
      "Step 0 Loss: 0.014233431778848171\n",
      "Step 0 Loss: 0.015181202441453934\n",
      "Step 0 Loss: 0.008375534787774086\n",
      "Step 0 Loss: 0.014026226475834846\n",
      "Step 0 Loss: 0.008266670629382133\n",
      "Step 0 Loss: 0.008310073055326939\n",
      "Step 0 Loss: 0.008264747448265553\n",
      "Step 0 Loss: 0.014929534867405891\n",
      "Step 0 Loss: 0.007042833603918552\n",
      "Step 0 Loss: 0.011138099245727062\n",
      "Step 0 Loss: 0.008270928636193275\n",
      "Step 0 Loss: 0.006782501935958862\n",
      "Step 0 Loss: 0.005253426730632782\n",
      "Step 0 Loss: 0.014752550050616264\n",
      "Step 0 Loss: 0.006517813075333834\n",
      "Step 0 Loss: 0.012929398566484451\n",
      "Step 0 Loss: 0.008194178342819214\n",
      "Step 0 Loss: 0.02201654762029648\n",
      "Step 0 Loss: 0.02752133645117283\n",
      "Step 0 Loss: 0.01642300747334957\n",
      "Step 0 Loss: 0.006730519235134125\n",
      "Step 0 Loss: 0.00539856031537056\n",
      "Step 0 Loss: 0.009600107558071613\n",
      "Step 0 Loss: 0.010521852411329746\n",
      "Step 0 Loss: 0.007007251493632793\n",
      "Step 0 Loss: 0.01107984408736229\n",
      "Step 0 Loss: 0.005116479471325874\n",
      "Step 0 Loss: 0.0322222076356411\n",
      "Step 0 Loss: 0.004782181233167648\n",
      "Step 0 Loss: 0.00873988401144743\n",
      "Step 0 Loss: 0.008339980617165565\n",
      "Step 0 Loss: 0.022519037127494812\n",
      "Step 0 Loss: 0.007627514190971851\n",
      "Step 0 Loss: 0.00773467356339097\n",
      "Step 0 Loss: 0.03111269511282444\n",
      "Step 0 Loss: 0.019061505794525146\n",
      "Step 0 Loss: 0.007545222993940115\n",
      "Step 0 Loss: 0.010111529380083084\n",
      "Step 0 Loss: 0.009545687586069107\n",
      "Step 0 Loss: 0.018666096031665802\n",
      "Step 0 Loss: 0.011510593816637993\n",
      "Step 0 Loss: 0.007331710308790207\n",
      "Step 0 Loss: 0.006140745710581541\n",
      "Step 0 Loss: 0.008074350655078888\n",
      "Step 0 Loss: 0.008669596165418625\n",
      "Step 0 Loss: 0.007888001389801502\n",
      "Step 0 Loss: 0.006432640366256237\n",
      "Step 0 Loss: 0.006533042993396521\n",
      "Step 0 Loss: 0.011814300902187824\n",
      "Step 0 Loss: 0.012498926371335983\n",
      "Step 0 Loss: 0.02983008325099945\n",
      "Step 0 Loss: 0.016067244112491608\n",
      "Step 0 Loss: 0.005294491536915302\n",
      "Step 0 Loss: 0.00572190573439002\n",
      "Step 0 Loss: 0.009744477458298206\n",
      "Step 0 Loss: 0.015518036670982838\n",
      "Step 0 Loss: 0.007999056950211525\n",
      "Step 0 Loss: 0.008007405325770378\n",
      "Step 0 Loss: 0.006432180758565664\n",
      "Step 0 Loss: 0.007702394388616085\n",
      "Step 0 Loss: 0.003873716341331601\n",
      "Step 0 Loss: 0.021551260724663734\n",
      "Step 0 Loss: 0.01176543440669775\n",
      "Step 0 Loss: 0.013615275733172894\n",
      "Step 0 Loss: 0.006613236386328936\n",
      "Step 0 Loss: 0.004373242612928152\n",
      "Step 0 Loss: 0.004348975606262684\n",
      "Step 0 Loss: 0.008424738422036171\n",
      "Step 0 Loss: 0.009515944868326187\n",
      "Step 0 Loss: 0.005783609114587307\n",
      "Step 0 Loss: 0.004986174404621124\n",
      "Step 0 Loss: 0.008926568552851677\n",
      "Step 0 Loss: 0.007861696183681488\n",
      "Step 0 Loss: 0.0025943955406546593\n",
      "Step 0 Loss: 0.014907671138644218\n",
      "Step 0 Loss: 0.005934892687946558\n",
      "Step 0 Loss: 0.009289450943470001\n",
      "Step 0 Loss: 0.006260368041694164\n",
      "Step 0 Loss: 0.008209367282688618\n",
      "Step 0 Loss: 0.004497116897255182\n",
      "Step 0 Loss: 0.012207510881125927\n",
      "Step 0 Loss: 0.012072780169546604\n",
      "Step 0 Loss: 0.01803077757358551\n",
      "Step 0 Loss: 0.005771360360085964\n",
      "Step 0 Loss: 0.00494768051430583\n",
      "Step 0 Loss: 0.013666128739714622\n",
      "Step 0 Loss: 0.004914979450404644\n",
      "Step 0 Loss: 0.0072391452267766\n",
      "Step 0 Loss: 0.010858248919248581\n",
      "Step 0 Loss: 0.004238671623170376\n",
      "Step 0 Loss: 0.007625820115208626\n",
      "Step 0 Loss: 0.006247916258871555\n",
      "Step 0 Loss: 0.004011919256299734\n",
      "Step 0 Loss: 0.004866980016231537\n",
      "Step 0 Loss: 0.0026650947984308004\n",
      "Step 0 Loss: 0.013003186322748661\n",
      "Step 0 Loss: 0.008169883862137794\n",
      "Step 0 Loss: 0.0076832240447402\n",
      "Step 0 Loss: 0.005723300855606794\n",
      "Step 0 Loss: 0.012603959068655968\n",
      "Step 0 Loss: 0.006569446995854378\n",
      "Step 0 Loss: 0.009226687252521515\n",
      "Step 0 Loss: 0.005848350934684277\n",
      "Step 0 Loss: 0.007801026571542025\n",
      "Step 0 Loss: 0.014551502652466297\n",
      "Step 0 Loss: 0.010481318458914757\n",
      "Step 0 Loss: 0.005482835695147514\n",
      "Step 0 Loss: 0.011422822251915932\n",
      "Step 0 Loss: 0.007862294092774391\n",
      "Step 0 Loss: 0.0089658098295331\n",
      "Step 0 Loss: 0.008019603788852692\n",
      "Step 0 Loss: 0.008161574602127075\n",
      "Step 0 Loss: 0.012835710309445858\n",
      "Step 0 Loss: 0.008508722297847271\n",
      "Step 0 Loss: 0.007850187830626965\n",
      "Step 0 Loss: 0.005821926053613424\n",
      "Step 0 Loss: 0.007569889537990093\n",
      "Step 0 Loss: 0.0029677911661565304\n",
      "Step 0 Loss: 0.005734326783567667\n",
      "Step 0 Loss: 0.009010016918182373\n",
      "Step 0 Loss: 0.0066864523105323315\n",
      "Step 0 Loss: 0.0046216705814003944\n",
      "Step 0 Loss: 0.00554273696616292\n",
      "Step 0 Loss: 0.008999789133667946\n",
      "Step 0 Loss: 0.025017114356160164\n",
      "Step 0 Loss: 0.005650355946272612\n",
      "Step 0 Loss: 0.019602283835411072\n",
      "Step 0 Loss: 0.0041452995501458645\n",
      "Step 0 Loss: 0.007165485993027687\n",
      "Step 0 Loss: 0.0052786231972277164\n",
      "Step 0 Loss: 0.004920227453112602\n",
      "Step 0 Loss: 0.004002168774604797\n",
      "Step 0 Loss: 0.008545709773898125\n",
      "Step 0 Loss: 0.006967219989746809\n",
      "Step 0 Loss: 0.0142663037404418\n",
      "Step 0 Loss: 0.004984501749277115\n",
      "Step 0 Loss: 0.0032706591300666332\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m d\u001b[38;5;241m.\u001b[39mgenerate_trajectories(number_of_trajectories,max_steps)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(replay_ratio \u001b[38;5;241m*\u001b[39m number_of_trajectories \u001b[38;5;241m*\u001b[39m max_steps \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size):\n\u001b[1;32m---> 23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pmaty\\Desktop\\RL_TUE\\HW\\rl-hockey-homework\\dreamer\\dreamer.py:63\u001b[0m, in \u001b[0;36mDreamerV3.train\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     60\u001b[0m indices, (obs, actions, rewards, dones, obs_next, latents, recurrent_hiddens) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39msample(batch_size)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Train the world model\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworld_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdones\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_next\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs_next\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_old\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_hiddens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m#self.memory.update(indices, latents=new_latents, recurrent_hidden=new_recurrent_hiddens)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\pmaty\\Desktop\\RL_TUE\\HW\\rl-hockey-homework\\dreamer\\world_model.py:333\u001b[0m, in \u001b[0;36mWorldModel.train\u001b[1;34m(self, x, a, r, c, x_next, z, h_old)\u001b[0m\n\u001b[0;32m    330\u001b[0m loss_total \u001b[38;5;241m=\u001b[39m loss_pred \u001b[38;5;241m+\u001b[39m loss_dyn \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m loss_enc\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 333\u001b[0m \u001b[43mloss_total\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_total\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\pmaty\\miniconda3\\envs\\rl_hw\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmaty\\miniconda3\\envs\\rl_hw\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmaty\\miniconda3\\envs\\rl_hw\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "env = h_env.HockeyEnv()\n",
    "\n",
    "d = dm.DreamerV3(\n",
    "\tenv=env,\n",
    "    obs_dim=env.observation_space.shape[0],\n",
    "    action_dim=env.action_space.shape[0] // 2,\n",
    "    latent_dim=8,\n",
    "    latent_categories_size=32,\n",
    "    model_dim=256,\n",
    "    imagination_horizon=15)\n",
    "\n",
    "replay_ratio = 3200\n",
    "number_of_training_steps = 1000\n",
    "batch_size = 32\n",
    "number_of_trajectories = 1\n",
    "max_steps = 100\n",
    "\n",
    "losses = []\n",
    "for step in range(number_of_training_steps):\n",
    "    d.generate_trajectories(number_of_trajectories,max_steps)\n",
    "\n",
    "    for _ in range(replay_ratio * number_of_trajectories * max_steps // batch_size):\n",
    "        loss = d.train(batch_size)\n",
    "        losses.append(loss)\n",
    "        print(f\"Step {step} Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
